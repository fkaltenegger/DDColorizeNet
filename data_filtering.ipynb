{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"data/colorization/flickr30k-images/\"\n",
    "image_path = random.choice(os.listdir(image_dir))\n",
    "img = Image.open(image_dir + image_path)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = img.convert(\"L\").convert(\"RGB\")\n",
    "bw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_variance(img_arr):\n",
    "    r, g, b = img_arr[:,:,0], img_arr[:,:,1], img_arr[:,:,2]\n",
    "    var_rg = (r - g).var() \n",
    "    var_gb = (g - b).var() \n",
    "    var_rb = (r - b).var()\n",
    "    return np.array([var_rg, var_gb, var_rb]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.array(img)\n",
    "bw_img_arr = np.array(bw_img)\n",
    "\n",
    "channel_variance(img_arr), channel_variance(bw_img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# target = io.imread(\"data/colorization/flickr30k-images/81641.jpg\")\n",
    "img = cv2.imread(\"data/colorization/flickr30k-images/81641.jpg\")\n",
    "LAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "cv2.imwrite('L.png', LAB[:,:,0])\n",
    "cv2.imwrite('a.png', LAB[:,:,1])\n",
    "cv2.imwrite('b.png', LAB[:,:,2])\n",
    "\n",
    "BGR = cv2.cvtColor(LAB, cv2.COLOR_LAB2RGB)\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('new.png', BGR)\n",
    "\n",
    "# target = color.rgb2lab(target / 255.0)\n",
    "# Image.fromarray(target.astype(np.uint8))\n",
    "# target\n",
    "# source = target[0:256, 0:256, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_var = 100\n",
    "image_dir = \"data/colorization/coco/\"\n",
    "while channel_var > 12:\n",
    "    image_path = random.choice(os.listdir(image_dir))\n",
    "    img = Image.open(image_dir + image_path)\n",
    "    img_arr = np.array(img)\n",
    "    channel_var = channel_variance(img_arr)\n",
    "print(channel_var)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"data/colorization/flickr30k-images/\"\n",
    "image_path = random.choice(os.listdir(image_dir))\n",
    "img = Image.open(image_dir + image_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "model = InstructBlipForConditionalGeneration.from_pretrained(\"Salesforce/instructblip-vicuna-7b\", torch_dtype=torch.float16)\n",
    "processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\", torch_dtype=torch.float16)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\").resize((512, 512))\n",
    "prompt = \"You are a professional photographer. Give a technical description of the colors of the main objects in this image and the overall color tone of the scene\"\n",
    "# prompt = \"You are an artist. Describe the main colors of this image and their temperature\"\n",
    "# prompt = \"As an expert in digital restoration, provide a technical assessment of the colors of the principal objects and the global color tone of this image.\",\n",
    "\n",
    "\n",
    "def blip_generate(text, image):\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            num_beams=5,\n",
    "            max_length=256,\n",
    "            min_length=1,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.5,\n",
    "            length_penalty=1.0,\n",
    "            temperature=1,\n",
    "        )\n",
    "        return processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(blip_generate(prompt, image))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blip_generate(prompt, img))\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matfuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
